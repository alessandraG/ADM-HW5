{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "graph = defaultdict(list)\n",
    "\n",
    "list1= list()\n",
    "with open(\"wiki-topcats-reduced.txt\") as f:\n",
    "        for line in f:\n",
    "            list1 = line.strip().split(\"\\t\")\n",
    "            if list1[0] in graph.keys():\n",
    "                graph[list1[0]].append(list1[1])\n",
    "            else:\n",
    "                graph[list1[0]]=[list1[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['401135', '1069112', '1163551']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the graph is not undirected because the node 52 has edge with 1099112 and the reverse is not true\n",
    "graph['52']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1060396',\n",
       " '1061304',\n",
       " '1062611',\n",
       " '1066969',\n",
       " '1069008',\n",
       " '1069113',\n",
       " '1069258',\n",
       " '1069275',\n",
       " '1656982']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph['1069112']b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to figure out the edges of the graph\n",
    "edges = []\n",
    "for e in graph:\n",
    "    a = graph[e]\n",
    "    for i in range(len(a)):\n",
    "        edges.append(a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2645247"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges) #2645247"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428957"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph.keys())\n",
    "#FOR SURE DIRECTED GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1= list()\n",
    "with open(\"wiki-topcats-reduced.txt\") as f:\n",
    "        for line in f:\n",
    "            list1.append(line.strip().split(\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to figure out the nodes of the graph\n",
    "nodes = []\n",
    "for e in list1:\n",
    "    nodes.append(e[0])\n",
    "    nodes.append(e[1])\n",
    "nodes=set(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461193"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes) #461193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average Node Degree\n",
    "count = 0\n",
    "for lst in graph.values():\n",
    "    count += len(lst)\n",
    "avgNodeDegree = count/len(graph.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.1666950300379755"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgNodeDegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2436602635647606e-05"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Density\n",
    "dense = len(edges)/(len(nodes)*(len(nodes)-1))\n",
    "dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we proved that the graph is directed we used Digraph function in networkx to create the graph\n",
    "import networkx as nx\n",
    "G=nx.DiGraph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the graph\n",
    "with open(\"wiki-topcats-reduced.txt\") as f:\n",
    "    for line in f:\n",
    "        list1 = line.strip().split(\"\\t\")\n",
    "        G.add_node(list1[0])\n",
    "        G.add_edge(list1[0],list1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### adding attribute 'Category' to each node of the graph\n",
    "\n",
    "for i in G:\n",
    "    G.node[i]['Category']=[]\n",
    "    \n",
    "from collections import defaultdict\n",
    "category_dict = defaultdict()\n",
    "\n",
    "with open(\"wiki-topcats-categories.txt\", \"r\") as f:\n",
    "    lst2=G.nodes()\n",
    "    for line in f:\n",
    "        cat_list = line.strip().split(\";\")\n",
    "        category = cat_list[0][9:]\n",
    "        lst = cat_list[1].strip().split(\" \")\n",
    "        if len(lst) > 3500:   \n",
    "            \n",
    "            lst1=[el for el in lst if el in lst2]\n",
    "            category_dict[category] = lst1\n",
    "\n",
    "#Assign attributes to each node\n",
    "for cat in category_dict:\n",
    "    lst=category_dict[cat]\n",
    "    for e in lst:\n",
    "        if e in G:\n",
    "            G.node[e]['Category'].append(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = list(category_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_category='indian_films'\n",
    "input_category='Indian_films'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tnrange, tqdm_notebook\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import threading\n",
    "# In our Algorithm for each root which is in the input category we go through graph, and each time we check each node attributes\n",
    "#if it is belonging to the categories that we are looking for and at the same time it doesn't belong to input category. \n",
    "#Therefore , each time the function is called , the nodes in the path of the roots are checked for 4 category\n",
    "\n",
    "def distance_graph(G, C0, C1):\n",
    "   \n",
    "    c0 = category_dict[C0][0:2000]\n",
    "\n",
    "    #with tqdm(total=value) as pbar:\n",
    "    shortest_paths_1 = list()\n",
    "    shortest_paths_2 = list()\n",
    "    shortest_paths_3 = list()\n",
    "    shortest_paths_4 = list()\n",
    "\n",
    "    for i in tnrange(len(c0)):\n",
    "        \n",
    "    #for i in range(len(c0)):\n",
    "        root=c0[i]\n",
    "        #pbar.write(\"proccesed: %d\"  %c0)\n",
    "        #pbar.update(1)\n",
    "        step = 0\n",
    "        seen=set([root])\n",
    "        queue=collections.deque([(root,step)])\n",
    "        while queue:\n",
    "            vertex=queue.popleft()\n",
    "            \n",
    "            \n",
    "            if C1[0] in G.node[vertex[0]]['Category'] and C0 not in G.node[vertex[0]]['Category']:\n",
    "                    shortest_paths_1.append(step)\n",
    "                 \n",
    "            elif C1[1] in G.node[vertex[0]]['Category'] and C0 not in G.node[vertex[0]]['Category']:\n",
    "                    shortest_paths_2.append(step)\n",
    "                   \n",
    "            \n",
    "            elif C1[2] in G.node[vertex[0]]['Category'] and C0 not in G.node[vertex[0]]['Category']:\n",
    "                    shortest_paths_3.append(step)\n",
    "                  \n",
    "            elif C1[3] in G.node[vertex[0]]['Category'] and C0 not in G.node[vertex[0]]['Category']:\n",
    "                    shortest_paths_4.append(step)\n",
    "                    \n",
    "            \n",
    "            neighbors1 = list(G[vertex[0]])\n",
    "            \n",
    "            step=vertex[1]+1\n",
    "            if neighbors1 == []:\n",
    "                continue\n",
    "              \n",
    "            \n",
    "            for i in neighbors1:\n",
    "                if i not in seen:\n",
    "                    queue.append((i,step))                    \n",
    "                    seen.add(i)\n",
    "                    \n",
    "    for i in range(len(C1)):\n",
    "        lc = len(category_dict[C1[i]])\n",
    "        \n",
    "        if len(eval('shortest_paths_%d'% (i+1))) != lc:\n",
    "            \n",
    "            diff = abs(len(eval('shortest_paths_%d'% (i+1))) - lc*len(c0))\n",
    "            #print(lc, diff, len(eval('shortest_paths_%d'% (i+1))))\n",
    "            aux_l = [math.inf for i in range(diff)]\n",
    "            eval(\"shortest_paths_{}\".format(i+1)).extend(aux_l)\n",
    "    \n",
    "    return [(C1[0], np.median(np.array(sorted(shortest_paths_1)))), (C1[1], np.median(np.array(sorted(shortest_paths_2)))),\n",
    "           (C1[2], np.median(np.array(sorted(shortest_paths_3)))), (C1[3], np.median(np.array(sorted(shortest_paths_4))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below created the list of lists for the first 16 categories \n",
    "auxiliary_list = list(category_dict.keys())\n",
    "auxiliary_list.remove(input_category)\n",
    "i=0\n",
    "lst=[]\n",
    "while i < 16:\n",
    "    lst.append(auxiliary_list[i:i+4])\n",
    "    i+=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the next list\n",
    "lst_2=[]\n",
    "while i<32:\n",
    "    lst_2.append(auxiliary_list[i:i+4])\n",
    "    i+=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Asteroids_named_for_people',\n",
       "  'English-language_albums',\n",
       "  'English_television_actors',\n",
       "  'British_films'],\n",
       " ['English-language_films',\n",
       "  'American_films',\n",
       "  'Fellows_of_the_Royal_Society',\n",
       "  'People_from_New_York_City'],\n",
       " ['American_Jews',\n",
       "  'American_television_actors',\n",
       "  'American_film_actors',\n",
       "  'Debut_albums'],\n",
       " ['Black-and-white_films',\n",
       "  'Year_of_birth_missing',\n",
       "  'Place_of_birth_missing_(living_people)',\n",
       "  'Article_Feedback_Pilot']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = []\n",
    "def threadGraph(lst):\n",
    "    res_list.append(distance_graph(G,input_category, lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Graphdf=pd.DataFrame()\n",
    "\n",
    "for i in res_list1:\n",
    "    Graphdf1=pd.DataFrame(i)\n",
    "    Graphdf=Graphdf.append(Graphdf1)\n",
    "Graphdf.to_csv(\"Graph1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76d0077458048909aba200313415f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08948c6ffd424e10a80108730a689cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcda437e795d40e1aa84d85d151d7334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443e28c60eb346668452e367e35bfe07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threads = []\n",
    "#four threads are created here\n",
    "for a in range(4):\n",
    "    t = threading.Thread(name = a, target = threadGraph1,\n",
    "                       args = [lst_2[a]])\n",
    "    \n",
    "    threads.append(t)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list1 = []\n",
    "def threadGraph1(lst):\n",
    "    res_list1.append(distance_graph(G,input_category, lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('English-language_films', 6.0),\n",
       "  ('American_films', inf),\n",
       "  ('Fellows_of_the_Royal_Society', 8.0),\n",
       "  ('People_from_New_York_City', 7.0)],\n",
       " [('Black-and-white_films', 7.0),\n",
       "  ('Year_of_birth_missing', inf),\n",
       "  ('Place_of_birth_missing_(living_people)', 8.0),\n",
       "  ('Article_Feedback_Pilot', 6.0)],\n",
       " [('Asteroids_named_for_people', inf),\n",
       "  ('English-language_albums', 7.0),\n",
       "  ('English_television_actors', 6.0),\n",
       "  ('British_films', 6.0)],\n",
       " [('American_Jews', 7.0),\n",
       "  ('American_television_actors', 6.0),\n",
       "  ('American_film_actors', inf),\n",
       "  ('Debut_albums', 7.0)]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the result is like below for each category the median shortest path\n",
    "res_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each time the out put of function in converted to dataframe and at the end these three dataframes are concated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English-language_films</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American_films</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fellows_of_the_Royal_Society</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>People_from_New_York_City</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black-and-white_films</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Year_of_birth_missing</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Place_of_birth_missing_(living_people)</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Article_Feedback_Pilot</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asteroids_named_for_people</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English-language_albums</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English_television_actors</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>British_films</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American_Jews</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American_television_actors</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American_film_actors</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Debut_albums</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0         1\n",
       "0                  English-language_films  6.000000\n",
       "1                          American_films       inf\n",
       "2            Fellows_of_the_Royal_Society  8.000000\n",
       "3               People_from_New_York_City  7.000000\n",
       "0                   Black-and-white_films  7.000000\n",
       "1                   Year_of_birth_missing       inf\n",
       "2  Place_of_birth_missing_(living_people)  8.000000\n",
       "3                  Article_Feedback_Pilot  6.000000\n",
       "0              Asteroids_named_for_people       inf\n",
       "1                 English-language_albums  7.000000\n",
       "2               English_television_actors  6.000000\n",
       "3                           British_films  6.000000\n",
       "0                           American_Jews  7.000000\n",
       "1              American_television_actors  6.000000\n",
       "2                    American_film_actors       inf\n",
       "3                            Debut_albums  7.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graphdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second part of category_list but the input list\n",
    "i=0\n",
    "lst_2=[]\n",
    "while i < 16:\n",
    "    lst_2.append(auxiliary_list[i:i+4])\n",
    "    i+=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "for a in range(4):\n",
    "    t = threading.Thread(name = a, target = threadGraph,\n",
    "                       args = [lst_2[a]])    \n",
    "    threads.append(t)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tnrange, tqdm_notebook\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "#@autojit\n",
    "def distance_graph2(G, C0, C1):\n",
    "   \n",
    "    c0 = category_dict[C0][0:2000]\n",
    "    #for i in range(len(C1)):\n",
    "        #exec(f'shortest_paths_{i}=[]')\n",
    "\n",
    "    #with tqdm(total=value) as pbar:\n",
    "    shortest_paths_1 = list()\n",
    "    shortest_paths_2 = list()\n",
    "    shortest_paths_3 = list()\n",
    "    #shortest_paths_4 = list()\n",
    "\n",
    "    for i in tnrange(len(c0)):\n",
    "        \n",
    "    #for i in range(len(c0)):\n",
    "        root=c0[i]\n",
    "        #pbar.write(\"proccesed: %d\"  %c0)\n",
    "        #pbar.update(1)\n",
    "        step = 0\n",
    "        seen=set([root])\n",
    "        queue=collections.deque([(root,step)])\n",
    "        while queue:\n",
    "            vertex=queue.popleft()\n",
    "            \n",
    "            \n",
    "            if C1[0] in G.node[vertex[0]]['Category'] and C0 not in G.node[vertex[0]]['Category']:\n",
    "                    shortest_paths_1.append(step)\n",
    "                 \n",
    "            elif C1[1] in G.node[vertex[0]]['Category'] and C0 not in G.node[vertex[0]]['Category']:\n",
    "                    shortest_paths_2.append(step)\n",
    "                   \n",
    "            \n",
    "            elif C1[2] in G.node[vertex[0]]['Category'] and C0 not in G.node[vertex[0]]['Category']:\n",
    "                    shortest_paths_3.append(step)\n",
    "                  \n",
    "            #elif C1[3] in G.node[vertex[0]]['Category'] and C0 not in G.node[vertex[0]]['Category']:\n",
    "                    #shortest_paths_4.append(step)\n",
    "                    \n",
    "            \n",
    "            neighbors1 = list(G[vertex[0]])\n",
    "            \n",
    "            step=vertex[1]+1\n",
    "            if neighbors1 == []:\n",
    "                continue\n",
    "              \n",
    "            \n",
    "            for i in neighbors1:\n",
    "                if i not in seen:\n",
    "                    queue.append((i,step))                    \n",
    "                    seen.add(i)\n",
    "                    \n",
    "    for i in range(len(C1)):\n",
    "        lc = len(category_dict[C1[i]])\n",
    "        \n",
    "        if len(eval('shortest_paths_%d'% (i+1))) != lc:\n",
    "            \n",
    "            diff = abs(len(eval('shortest_paths_%d'% (i+1))) - lc*len(c0))\n",
    "            #print(lc, diff, len(eval('shortest_paths_%d'% (i+1))))\n",
    "            aux_l = [math.inf for i in range(diff)]\n",
    "            eval(\"shortest_paths_{}\".format(i+1)).extend(aux_l)\n",
    "    \n",
    "    return [(C1[0], np.median(np.array(sorted(shortest_paths_1)))), (C1[1], np.median(np.array(sorted(shortest_paths_2))))]\n",
    "           (C1[2], np.median(np.array(sorted(shortest_paths_3)))), #(C1[3], np.median(np.array(sorted(shortest_paths_4))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73db61b1b504f9c9418ae4e6872bbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "d=distance_graph2(G,input_category,['American_military_personnel_of_World_War_II', 'Windows_games','Indian_films'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graphdf=pd.DataFrame()\n",
    "Graphdf=Graphdf.append(d)\n",
    "Graphdf.to_csv(\"Graph3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=pd.read_csv('Graphdf1.csv')\n",
    "dfg1 = pd.read_csv('Graphdf2.csv')\n",
    "dfg2 = pd.read_csv('Graph3.csv')\n",
    "dfg = dfg.drop(columns=\"Unnamed: 0\")\n",
    "dfg1 = dfg1.drop(columns=\"Unnamed: 0\")\n",
    "dfg2 = dfg2.drop(columns=\"Unnamed: 0\")\n",
    "dfg=dfg.reset_index(drop=True)\n",
    "dfg = dfg.rename(columns={\"0\": \"Category\", \"1\": \"Distance\"})\n",
    "dfg = dfg.sort_values(by='Distance')\n",
    "dfg = dfg.reset_index(drop=True)\n",
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg.to_csv('ranking_table.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
